{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f103fb0776c84526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:08:01.822849Z",
     "start_time": "2025-01-11T12:08:01.818145Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 18:32:07.698124: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-14 18:32:08.725156: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-01-14 18:32:08.725283: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-01-14 18:32:08.725294: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten,Subtract,Reshape\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D,Conv2D,MaxPooling2D,Input,Lambda,GlobalMaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from skimage.io import imsave\n",
    "\n",
    "from matplotlib.pyplot import imread\n",
    "from skimage.transform import rescale, resize\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca455707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "tf.__version__, keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c24f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd68d1cfd4ece7f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T11:43:51.213241Z",
     "start_time": "2025-01-11T11:43:51.205253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_5973/337460670.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 18:32:15.388994: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-14 18:32:15.777264: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-14 18:32:16.066547: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-14 18:32:16.066652: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-14 18:32:17.961699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-14 18:32:17.962467: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-14 18:32:17.962502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-01-14 18:32:17.962669: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-14 18:32:17.963201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 3906 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca7f3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 18:32:17.986132: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-14 18:32:17.986380: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-14 18:32:17.986510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "587e65bf150e5182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:22:28.121966Z",
     "start_time": "2025-01-11T12:22:28.114515Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "\"\"\"\n",
    "dataset_path = '../../../data/processed/smallerSampleDataset/'\n",
    "reshape_size = [224,224,3]\n",
    "phishing_test_size = 0.4\n",
    "num_targets = 155\n",
    "\"\"\"\n",
    "\n",
    "dataset_config = {\n",
    "    \"dataset_path\": '../../../data/processed/smallerSampleDataset/',\n",
    "    \"reshape_size\": [224, 224, 3],\n",
    "    \"phishing_test_size\": 0.4,\n",
    "    \"num_targets\": 5\n",
    "}\n",
    "\n",
    "# Model parameters\n",
    "\"\"\"\n",
    "input_shape = [224,224,3]\n",
    "margin = 2.2\n",
    "new_conv_params = [5,5,512]\n",
    "\"\"\"\n",
    "\n",
    "model_config = {\n",
    "    'input_shape': [224, 224, 3],\n",
    "    'margin': 2.2,\n",
    "    'new_conv_params': [5, 5, 512]\n",
    "}\n",
    "\n",
    "# Training parameters\n",
    "\"\"\" original params\n",
    "start_lr = 0.00002\n",
    "output_dir = '../../../notebooks/'\n",
    "saved_model_name = 'model'\n",
    "save_interval = 2000\n",
    "batch_size = 32\n",
    "n_iter = 21000\n",
    "lr_interval = 100\n",
    "\"\"\"\n",
    "\n",
    "training_config = {\n",
    "    \"start_lr\": 0.00002,\n",
    "    'output_dir': '../../../notebooks/',\n",
    "    \"saved_model_name\": 'model',\n",
    "    'save_interval': 200,\n",
    "    \"batch_size\": 32,  \n",
    "    \"n_iter\": 210,\n",
    "    \"lr_interval\":100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9752c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "dataset_path = dataset_config['dataset_path']\n",
    "reshape_size = dataset_config['reshape_size']\n",
    "phishing_test_size = dataset_config['phishing_test_size']\n",
    "num_targets = dataset_config['num_targets']\n",
    "\n",
    "# Model parameters\n",
    "input_shape = model_config['input_shape']\n",
    "margin = model_config['margin']\n",
    "new_conv_params = model_config['new_conv_params']\n",
    "\n",
    "# Training parameters\n",
    "start_lr = training_config['start_lr']\n",
    "output_dir = training_config['output_dir']\n",
    "saved_model_name = training_config['saved_model_name']\n",
    "save_interval = training_config['save_interval']\n",
    "batch_size =training_config['batch_size']\n",
    "n_iter = training_config['n_iter']\n",
    "lr_interval = training_config['lr_interval']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6792c6cc68cbbfa",
   "metadata": {},
   "source": [
    "# Load dataset:\n",
    "    - Load training screenshots per website\n",
    "    - Load Phishing screenshots per website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f198ccb8110d6ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:14:39.967202Z",
     "start_time": "2025-01-11T12:14:39.960937Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_imgs_per_website(data_path,targets,imgs_num,reshape_size,start_target_count):\n",
    "    all_imgs = np.zeros(shape=[imgs_num,224,224,3])\n",
    "    all_labels = np.zeros(shape=[imgs_num,1])\n",
    "\n",
    "    all_file_names = []\n",
    "    targets_list = targets.splitlines()\n",
    "    count = 0\n",
    "    for i in range(0,len(targets_list)):\n",
    "        target_path = data_path + targets_list[i]\n",
    "        print(target_path)\n",
    "        file_names = sorted(os.listdir(target_path))\n",
    "        for j in range(0,len(file_names)):\n",
    "            try:\n",
    "                img = imread(target_path+'/'+file_names[j])\n",
    "                img = img[:,:,0:3]\n",
    "                all_imgs[count,:,:,:] = resize(img, (reshape_size[0], reshape_size[1]),anti_aliasing=True)\n",
    "                all_labels[count,:] = i + start_target_count\n",
    "                all_file_names.append(file_names[j])\n",
    "                count = count + 1\n",
    "            except:\n",
    "                #some images were saved with a wrong extensions\n",
    "                try:\n",
    "                    img = imread(target_path+'/'+file_names[j],format='jpeg')\n",
    "                    img = img[:,:,0:3]\n",
    "                    all_imgs[count,:,:,:] = resize(img, (reshape_size[0], reshape_size[1]),anti_aliasing=True)\n",
    "                    all_labels[count,:] = i + start_target_count\n",
    "                    all_file_names.append(file_names[j])\n",
    "                    count = count + 1\n",
    "                except:\n",
    "                    print('failed at:')\n",
    "                    print('***')\n",
    "                    print(file_names[j])\n",
    "                    break\n",
    "    return all_imgs,all_labels,all_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84276bbda72fc59d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:22:31.148231Z",
     "start_time": "2025-01-11T12:22:31.095287Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read images legit (train)\n",
    "data_path = dataset_path + 'trusted_list/'\n",
    "targets_file = open(data_path+'targets.txt', \"r\")\n",
    "targets = targets_file.read()\n",
    "# imgs_num = 9363\n",
    "imgs_num = 420\n",
    "all_imgs_train,all_labels_train,all_file_names_train = read_imgs_per_website(data_path,targets,imgs_num,reshape_size,0)\n",
    "\n",
    "# Read images phishing\n",
    "data_path = dataset_path + 'phishing/'\n",
    "targets_file = open(data_path+'targets.txt', \"r\")\n",
    "targets = targets_file.read()\n",
    "# imgs_num = 1195\n",
    "imgs_num = 160\n",
    "all_imgs_test,all_labels_test,all_file_names_test = read_imgs_per_website(data_path,targets,imgs_num,reshape_size,0)\n",
    "\n",
    "X_train_legit = all_imgs_train\n",
    "y_train_legit = all_labels_train\n",
    "\n",
    "# Split phishing to training and test, load train and test indices.\n",
    "idx_test = np.load(output_dir+'test_idx.npy')\n",
    "idx_train = np.load(output_dir+'train_idx.npy')\n",
    "X_test_phish = all_imgs_test[idx_test,:]\n",
    "y_test_phish = all_labels_test[idx_test,:]\n",
    "X_train_phish = all_imgs_test[idx_train,:]\n",
    "y_train_phish = all_labels_test[idx_train,:]\n",
    "\n",
    "#otherwise, make a new split here.\n",
    "\n",
    "# idx = np.arange(all_imgs_test.shape[0])\n",
    "# X_test_phish, X_train_phish, y_test_phish, y_train_phish,idx_test,idx_train = train_test_split(all_imgs_test, all_labels_test,idx, test_size=phishing_test_size)\n",
    "# np.save(output_dir+'test_idx',idx_test)\n",
    "# np.save(output_dir+'train_idx',idx_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(all_imgs_train, output_dir+'all_imgs_train')\n",
    "joblib.dump(all_labels_train, output_dir+'all_labels_train')\n",
    "\n",
    "joblib.dump(all_imgs_test, output_dir+'all_imgs_test')\n",
    "joblib.dump(all_labels_test, output_dir+'all_labels_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc2a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Split phishing to training and test, load train and test indices.\n",
    "all_imgs_train = joblib.load(output_dir+'all_imgs_train')\n",
    "all_labels_train = joblib.load(output_dir+'all_labels_train')\n",
    "\n",
    "all_imgs_test = joblib.load(output_dir+'all_imgs_test')\n",
    "all_labels_test = joblib.load(output_dir+'all_labels_test')\n",
    "\n",
    "X_train_legit = all_imgs_train\n",
    "y_train_legit = all_labels_train\n",
    "\n",
    "idx_test = np.load(output_dir+'test_idx.npy')\n",
    "idx_train = np.load(output_dir+'train_idx.npy')\n",
    "X_test_phish = all_imgs_test[idx_test,:]\n",
    "y_test_phish = all_labels_test[idx_test,:]\n",
    "X_train_phish = all_imgs_test[idx_train,:]\n",
    "y_train_phish = all_labels_test[idx_train,:]\n",
    "\n",
    "data_path = dataset_path + 'phishing/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdea5879f14d2f98",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8774a59a9c4fda8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_triplet_network(input_shape, new_conv_params):\n",
    "\n",
    "    # Input_shape: shape of input images\n",
    "    # new_conv_params: dimension of the new convolution layer [spatial1,spatial2,channels]\n",
    "\n",
    "    # Define the tensors for the three input images\n",
    "    anchor_input = Input(input_shape)\n",
    "    positive_input = Input(input_shape)\n",
    "    negative_input = Input(input_shape)\n",
    "\n",
    "    # Use VGG as a base model\n",
    "    base_model = VGG16(weights='imagenet',  input_shape=input_shape, include_top=False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Conv2D(new_conv_params[2],(new_conv_params[0],new_conv_params[1]),activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(2e-4)) (x)\n",
    "    x = GlobalMaxPooling2D() (x)\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_a = model(anchor_input)\n",
    "    encoded_p = model(positive_input)\n",
    "    encoded_n = model(negative_input)\n",
    "\n",
    "    mean_layer = Lambda(lambda x: K.mean(x,axis=1))\n",
    "\n",
    "    square_diff_layer = Lambda(lambda tensors:K.square(tensors[0] - tensors[1]))\n",
    "    square_diff_pos = square_diff_layer([encoded_a,encoded_p])\n",
    "    square_diff_neg = square_diff_layer([encoded_a,encoded_n])\n",
    "\n",
    "    square_diff_pos_l2 = mean_layer(square_diff_pos)\n",
    "    square_diff_neg_l2 = mean_layer(square_diff_neg)\n",
    "\n",
    "    # Add a diff layer\n",
    "    diff = Subtract()([square_diff_pos_l2, square_diff_neg_l2])\n",
    "    diff = Reshape((1,)) (diff)\n",
    "\n",
    "    # Connect the inputs with the outputs\n",
    "    triplet_net = Model(inputs=[anchor_input,positive_input,negative_input],outputs=diff)\n",
    "\n",
    "    # return the model\n",
    "    return triplet_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4040fc7de1becec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 18:32:33.433063: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-14 18:32:33.433237: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-14 18:32:33.433313: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-14 18:32:33.433674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-14 18:32:33.433693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-01-14 18:32:33.433750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-14 18:32:33.433778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3906 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 512)          21268800    ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 512)          0           ['model[0][0]',                  \n",
      "                                                                  'model[1][0]',                  \n",
      "                                                                  'model[0][0]',                  \n",
      "                                                                  'model[2][0]']                  \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None,)              0           ['lambda_1[0][0]',               \n",
      "                                                                  'lambda_1[1][0]']               \n",
      "                                                                                                  \n",
      " subtract (Subtract)            (None,)              0           ['lambda[0][0]',                 \n",
      "                                                                  'lambda[1][0]']                 \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1)            0           ['subtract[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,268,800\n",
      "Trainable params: 21,268,800\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarcin/inz/src/models/visualphishnet/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the triplet loss\n",
    "# Create and compile model\n",
    "\n",
    "def custom_loss(margin):\n",
    "    def loss(y_true,y_pred):\n",
    "        loss_value = K.maximum(y_true, margin + y_pred)\n",
    "        loss_value = K.mean(loss_value,axis=0)\n",
    "        return loss_value\n",
    "    return loss\n",
    "def loss(y_true,y_pred):\n",
    "    loss_value = K.maximum(y_true, margin + y_pred)\n",
    "    loss_value = K.mean(loss_value,axis=0)\n",
    "    return loss_value\n",
    "\n",
    "\n",
    "model = define_triplet_network(input_shape, new_conv_params)\n",
    "model.summary()\n",
    "\n",
    "from keras import optimizers\n",
    "optimizer = optimizers.Adam(lr = start_lr)\n",
    "model.compile(loss=custom_loss(margin),optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe4c1e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_1, Trainable: True\n",
      "Layer: input_2, Trainable: True\n",
      "Layer: input_3, Trainable: True\n",
      "Layer: model, Trainable: True\n",
      "Layer: lambda_1, Trainable: True\n",
      "Layer: lambda, Trainable: True\n",
      "Layer: subtract, Trainable: True\n",
      "Layer: reshape, Trainable: True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(f\"Layer: {layer.name}, Trainable: {layer.trainable}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec271d40ede24508",
   "metadata": {},
   "source": [
    "# Triplet Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c880c705e7ecefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order random phishing arrays per website (from 0 to 155 target)\n",
    "\n",
    "def order_random_array(orig_arr,y_orig_arr,targets):\n",
    "    sorted_arr = np.zeros(orig_arr.shape)\n",
    "    y_sorted_arr = np.zeros(y_orig_arr.shape)\n",
    "    count = 0\n",
    "    for i in range(0,targets):\n",
    "        for j in range(0,orig_arr.shape[0]):\n",
    "            if y_orig_arr[j] == i:\n",
    "                sorted_arr[count,:,:,:] = orig_arr[j,:,:,:]\n",
    "                y_sorted_arr[count,:] = i\n",
    "                count = count + 1\n",
    "    return sorted_arr,y_sorted_arr\n",
    "\n",
    "X_test_phish,y_test_phish = order_random_array(X_test_phish,y_test_phish,num_targets)\n",
    "X_train_phish,y_train_phish = order_random_array(X_train_phish,y_train_phish,num_targets)\n",
    "\n",
    "\n",
    "# Store the start and end of each target in the phishing set (used later in triplet sampling)\n",
    "# Not all targets might be in the phishing set\n",
    "def targets_start_end(num_target,labels):\n",
    "    prev_target = labels[0]\n",
    "    start_end_each_target = np.zeros((num_target,2))\n",
    "    start_end_each_target[0,0] = labels[0]\n",
    "    if not labels[0] == 0:\n",
    "        start_end_each_target[0,0] = -1\n",
    "        start_end_each_target[0,1] = -1\n",
    "    count_target = 0\n",
    "    for i in range(1,labels.shape[0]):\n",
    "        if not labels[i] == prev_target:\n",
    "            start_end_each_target[int(labels[i-1]),1] = int(i-1)\n",
    "            start_end_each_target[int(labels[i]),0] = int(i)\n",
    "            prev_target = labels[i]\n",
    "    start_end_each_target[int(labels[-1]),1] = int(labels.shape[0]-1)\n",
    "\n",
    "    for i in range(1,num_target):\n",
    "        if start_end_each_target[i,0] == 0:\n",
    "            start_end_each_target[i,0] = -1\n",
    "            start_end_each_target[i,1] = -1\n",
    "    return start_end_each_target\n",
    "\n",
    "labels_start_end_train_phish = targets_start_end(num_targets,y_train_phish)\n",
    "labels_start_end_test_phish = targets_start_end(num_targets,y_test_phish)\n",
    "\n",
    "\n",
    "# Store the start and end of each target in the training set (used later in triplet sampling)\n",
    "def all_targets_start_end(num_target,labels):\n",
    "    prev_target = 0\n",
    "    start_end_each_target = np.zeros((num_target,2))\n",
    "    start_end_each_target[0,0] = 0\n",
    "    count_target = 0\n",
    "    for i in range(1,labels.shape[0]):\n",
    "        if not labels[i] == prev_target:\n",
    "            start_end_each_target[count_target,1] = i-1\n",
    "            count_target = count_target + 1\n",
    "            start_end_each_target[count_target,0] = i\n",
    "            prev_target = prev_target + 1\n",
    "    start_end_each_target[num_target-1,1] = labels.shape[0]-1\n",
    "    return start_end_each_target\n",
    "\n",
    "labels_start_end_train_legit = all_targets_start_end(num_targets,y_train_legit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ec2431d607680ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample anchor, positive and negative images\n",
    "def pick_first_img_idx(labels_start_end,num_targets):\n",
    "    random_target = -1\n",
    "    while (random_target == -1):\n",
    "        random_target = np.random.randint(low = 0,high = num_targets)\n",
    "        if labels_start_end[random_target,0] == -1:\n",
    "            random_target = -1\n",
    "    return random_target\n",
    "\n",
    "def pick_pos_img_idx(prob_phish,img_label):\n",
    "    if np.random.uniform() > prob_phish:\n",
    "        class_idx_start_end = labels_start_end_train_legit[img_label,:]\n",
    "        same_idx = np.random.randint(low = class_idx_start_end[0],high = class_idx_start_end[1]+1)\n",
    "        img = X_train_legit[same_idx,:]\n",
    "    else:\n",
    "        if not labels_start_end_train_phish[img_label,0] == -1:\n",
    "            class_idx_start_end = labels_start_end_train_phish[img_label,:]\n",
    "            same_idx = np.random.randint(low = class_idx_start_end[0],high = class_idx_start_end[1]+1)\n",
    "            img = X_train_phish[same_idx,:]\n",
    "        else:\n",
    "            class_idx_start_end = labels_start_end_train_legit[img_label,:]\n",
    "            same_idx = np.random.randint(low = class_idx_start_end[0],high = class_idx_start_end[1]+1)\n",
    "            img = X_train_legit[same_idx,:]\n",
    "    return img\n",
    "\n",
    "def pick_neg_img(anchor_idx,num_targets):\n",
    "    if anchor_idx == 0:\n",
    "        targets = np.arange(1,num_targets)\n",
    "    elif anchor_idx == num_targets -1:\n",
    "        targets = np.arange(0,num_targets-1)\n",
    "    else:\n",
    "        targets = np.concatenate([np.arange(0,anchor_idx),np.arange(anchor_idx+1,num_targets)])\n",
    "    diff_target_idx = np.random.randint(low = 0,high = num_targets-1)\n",
    "    diff_target = targets[diff_target_idx]\n",
    "\n",
    "    class_idx_start_end = labels_start_end_train_legit[diff_target,:]\n",
    "    idx_from_diff_target = np.random.randint(low = class_idx_start_end[0],high = class_idx_start_end[1]+1)\n",
    "    img = X_train_legit[idx_from_diff_target,:]\n",
    "\n",
    "    return img,diff_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54b95a127651c60",
   "metadata": {},
   "source": [
    "# Sample batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "295d0cd33c236d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't sample negative image from the same category as the positive image (e.g. google and google drive)\n",
    "# Create clusters of same-company websites (e.g. all microsoft websites)\n",
    "\n",
    "\n",
    "targets_file = open(data_path+'targets.txt', \"r\")\n",
    "all_targets = targets_file.read()\n",
    "all_targets = all_targets.splitlines()\n",
    "\n",
    "def get_idx_of_target(target_name,all_targets):\n",
    "    for i in range(0,len(all_targets)):\n",
    "        if all_targets[i] == target_name:\n",
    "            found_idx = i\n",
    "            return found_idx\n",
    "\n",
    "#targets names of parent and sub websites\n",
    "target_lists = [['microsoft','ms_outlook','ms_office','ms_bing','ms_onedrive','ms_skype'],['apple','itunes','icloud'],['google','google_drive'],['alibaba','aliexpress']]\n",
    "\n",
    "def get_associated_targets_idx(target_lists,all_targets):\n",
    "    sub_target_lists_idx = []\n",
    "    parents_ids = []\n",
    "    for i in range(0,len(target_lists)):\n",
    "        target_list = target_lists[i]\n",
    "        parent_target = target_list[0]\n",
    "        one_target_list = []\n",
    "        parent_idx = get_idx_of_target(parent_target,all_targets)\n",
    "        parents_ids.append(parent_idx)\n",
    "        for child_target in target_list[1:]:\n",
    "            child_idx = get_idx_of_target(child_target,all_targets)\n",
    "            one_target_list.append(child_idx)\n",
    "        sub_target_lists_idx.append(one_target_list)\n",
    "    return parents_ids,sub_target_lists_idx\n",
    "\n",
    "parents_ids,sub_target_lists_idx  = get_associated_targets_idx(target_lists,all_targets)\n",
    "\n",
    "def check_if_same_category(img_label1,img_label2):\n",
    "    if_same = 0\n",
    "    if img_label1 in parents_ids:\n",
    "        if img_label2 in sub_target_lists_idx[parents_ids.index(img_label1)]:\n",
    "            if_same = 1\n",
    "    elif img_label1 in sub_target_lists_idx[0]:\n",
    "        if img_label2 in sub_target_lists_idx[0] or img_label2 == parents_ids[0]:\n",
    "            if_same = 1\n",
    "    elif img_label1 in sub_target_lists_idx[1]:\n",
    "        if img_label2 in sub_target_lists_idx[1] or img_label2 == parents_ids[1]:\n",
    "            if_same = 1\n",
    "    elif img_label1 in sub_target_lists_idx[2]:\n",
    "        if img_label2 in sub_target_lists_idx[2] or img_label2 == parents_ids[2]:\n",
    "            if_same = 1\n",
    "    return if_same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc01afe6aefc361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample triplets\n",
    "def get_batch(batch_size,num_targets):\n",
    "\n",
    "    # initialize 3 empty arrays for the input image batch\n",
    "    h = X_train_legit.shape[1]\n",
    "    w = X_train_legit.shape[2]\n",
    "    triple=[np.zeros((batch_size, h, w,3)) for i in range(3)]\n",
    "\n",
    "    for i in range(0,batch_size):\n",
    "        img_idx_pair1 = pick_first_img_idx(labels_start_end_train_legit,num_targets)\n",
    "        triple[0][i,:,:,:] = X_train_legit[img_idx_pair1,:]\n",
    "        img_label = int(y_train_legit[img_idx_pair1])\n",
    "\n",
    "        # get image for the second: positive\n",
    "        triple[1][i,:,:,:] = pick_pos_img_idx(0.15,img_label)\n",
    "\n",
    "        # get image for the thrid: negative from legit\n",
    "        # don't sample from the same cluster\n",
    "        img_neg,label_neg = pick_neg_img(img_label,num_targets)\n",
    "        while check_if_same_category(img_label,label_neg) == 1:\n",
    "            img_neg,label_neg = pick_neg_img(img_label,num_targets)\n",
    "\n",
    "        triple[2][i,:,:,:] = img_neg\n",
    "\n",
    "    return triple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd920340523c19b0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fc835de940673a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_keras_model(model):\n",
    "    model.save(output_dir+saved_model_name+'.h5')\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3a5baff2f317429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training process!\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 18:39:15.689229: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8904\n",
      "2025-01-14 18:39:18.790529: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-01-14 18:39:18.790622: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-01-14 18:39:18.872295: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-01-14 18:39:18.872390: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-01-14 18:39:18.912928: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-01-14 18:39:18.913045: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-01-14 18:39:19.653005: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 939.37MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-01-14 18:39:19.653072: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 939.37MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-01-14 18:39:19.785880: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 939.37MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-01-14 18:39:19.785941: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 939.37MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-01-14 18:39:22.293451: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 1073741824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:22.293508: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 1073741824\n",
      "2025-01-14 18:39:22.361834: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 966367744 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:22.361880: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 966367744\n",
      "2025-01-14 18:39:22.504615: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 869731072 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:22.505620: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 869731072\n",
      "2025-01-14 18:39:22.976334: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 782758144 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:22.976517: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 782758144\n",
      "2025-01-14 18:39:23.620790: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 704482304 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:23.621293: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 704482304\n",
      "2025-01-14 18:39:24.134003: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 634034176 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:24.134135: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 634034176\n",
      "2025-01-14 18:39:24.289693: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 570630912 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:24.289789: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 570630912\n",
      "2025-01-14 18:39:24.593384: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 513568000 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:24.593467: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 513568000\n",
      "2025-01-14 18:39:24.736002: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 462211328 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:24.736069: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 462211328\n",
      "2025-01-14 18:39:24.808117: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 415990272 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:24.808191: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 415990272\n",
      "2025-01-14 18:39:24.879055: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 1073741824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:24.879121: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 1073741824\n",
      "2025-01-14 18:39:25.423163: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 1073741824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:25.423333: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 1073741824\n",
      "2025-01-14 18:39:25.697866: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 1073741824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:25.697993: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 1073741824\n",
      "2025-01-14 18:39:26.660732: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 1073741824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:26.660790: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 1073741824\n",
      "2025-01-14 18:39:26.753860: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 1073741824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:26.753913: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 1073741824\n",
      "2025-01-14 18:39:34.948429: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 1073741824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:34.948495: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 1073741824\n",
      "2025-01-14 18:39:35.024288: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 1073741824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:35.024329: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 1073741824\n",
      "2025-01-14 18:39:35.024347: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (gpu_host_bfc) ran out of memory trying to allocate 392.00MiB (rounded to 411041792)requested by op swap_out_gradient_tape/model_1/model/block1_conv1/ReluGrad_1_1\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-01-14 18:39:35.024355: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for gpu_host_bfc\n",
      "2025-01-14 18:39:35.024393: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 90, Chunks in use: 90. 22.5KiB allocated for chunks. 22.5KiB in use in bin. 1.3KiB client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024406: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024413: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024418: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024424: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024428: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024433: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024438: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024443: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024447: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024465: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024470: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024477: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 0. 1.98MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024482: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024487: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024492: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024498: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024506: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 2, Chunks in use: 0. 64.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024511: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024517: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024524: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 2. 1.00GiB allocated for chunks. 1.00GiB in use in bin. 784.00MiB client-requested in use in bin.\n",
      "2025-01-14 18:39:35.024531: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 392.00MiB was 256.00MiB, Chunk State: \n",
      "2025-01-14 18:39:35.024535: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 2097152\n",
      "2025-01-14 18:39:35.024545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800000 of size 256 next 1\n",
      "2025-01-14 18:39:35.024549: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800100 of size 256 next 2\n",
      "2025-01-14 18:39:35.024553: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800200 of size 256 next 3\n",
      "2025-01-14 18:39:35.024557: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800300 of size 256 next 4\n",
      "2025-01-14 18:39:35.024561: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800400 of size 256 next 5\n",
      "2025-01-14 18:39:35.024565: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800500 of size 256 next 6\n",
      "2025-01-14 18:39:35.024569: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800600 of size 256 next 7\n",
      "2025-01-14 18:39:35.024572: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800700 of size 256 next 8\n",
      "2025-01-14 18:39:35.024576: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800800 of size 256 next 9\n",
      "2025-01-14 18:39:35.024580: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800900 of size 256 next 10\n",
      "2025-01-14 18:39:35.024584: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800a00 of size 256 next 11\n",
      "2025-01-14 18:39:35.024588: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800b00 of size 256 next 12\n",
      "2025-01-14 18:39:35.024592: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800c00 of size 256 next 13\n",
      "2025-01-14 18:39:35.024596: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800d00 of size 256 next 14\n",
      "2025-01-14 18:39:35.024600: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800e00 of size 256 next 15\n",
      "2025-01-14 18:39:35.024603: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800f00 of size 256 next 16\n",
      "2025-01-14 18:39:35.024607: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801000 of size 256 next 17\n",
      "2025-01-14 18:39:35.024610: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801100 of size 256 next 18\n",
      "2025-01-14 18:39:35.024614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801200 of size 256 next 19\n",
      "2025-01-14 18:39:35.024618: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801300 of size 256 next 20\n",
      "2025-01-14 18:39:35.024621: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801400 of size 256 next 21\n",
      "2025-01-14 18:39:35.024625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801500 of size 256 next 22\n",
      "2025-01-14 18:39:35.024629: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801600 of size 256 next 23\n",
      "2025-01-14 18:39:35.024633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801700 of size 256 next 24\n",
      "2025-01-14 18:39:35.024637: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801800 of size 256 next 25\n",
      "2025-01-14 18:39:35.024641: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801900 of size 256 next 26\n",
      "2025-01-14 18:39:35.024645: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801a00 of size 256 next 27\n",
      "2025-01-14 18:39:35.024649: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801b00 of size 256 next 28\n",
      "2025-01-14 18:39:35.024653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801c00 of size 256 next 29\n",
      "2025-01-14 18:39:35.024657: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801d00 of size 256 next 30\n",
      "2025-01-14 18:39:35.024660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801e00 of size 256 next 31\n",
      "2025-01-14 18:39:35.024663: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801f00 of size 256 next 32\n",
      "2025-01-14 18:39:35.024667: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802000 of size 256 next 33\n",
      "2025-01-14 18:39:35.024671: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802100 of size 256 next 34\n",
      "2025-01-14 18:39:35.024675: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802200 of size 256 next 35\n",
      "2025-01-14 18:39:35.024678: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802300 of size 256 next 36\n",
      "2025-01-14 18:39:35.024682: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802400 of size 256 next 37\n",
      "2025-01-14 18:39:35.024686: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802500 of size 256 next 38\n",
      "2025-01-14 18:39:35.024690: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802600 of size 256 next 39\n",
      "2025-01-14 18:39:35.024693: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802700 of size 256 next 40\n",
      "2025-01-14 18:39:35.024697: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802800 of size 256 next 41\n",
      "2025-01-14 18:39:35.024700: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802900 of size 256 next 42\n",
      "2025-01-14 18:39:35.024703: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802a00 of size 256 next 43\n",
      "2025-01-14 18:39:35.024706: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802b00 of size 256 next 44\n",
      "2025-01-14 18:39:35.024710: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802c00 of size 256 next 45\n",
      "2025-01-14 18:39:35.024714: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802d00 of size 256 next 46\n",
      "2025-01-14 18:39:35.024717: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802e00 of size 256 next 47\n",
      "2025-01-14 18:39:35.024721: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802f00 of size 256 next 48\n",
      "2025-01-14 18:39:35.024724: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803000 of size 256 next 49\n",
      "2025-01-14 18:39:35.024728: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803100 of size 256 next 50\n",
      "2025-01-14 18:39:35.024732: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803200 of size 256 next 51\n",
      "2025-01-14 18:39:35.024735: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803300 of size 256 next 52\n",
      "2025-01-14 18:39:35.024739: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803400 of size 256 next 53\n",
      "2025-01-14 18:39:35.024742: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803500 of size 256 next 54\n",
      "2025-01-14 18:39:35.024745: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803600 of size 256 next 55\n",
      "2025-01-14 18:39:35.024747: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803700 of size 256 next 56\n",
      "2025-01-14 18:39:35.024750: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803800 of size 256 next 57\n",
      "2025-01-14 18:39:35.024754: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803900 of size 256 next 58\n",
      "2025-01-14 18:39:35.024758: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803a00 of size 256 next 59\n",
      "2025-01-14 18:39:35.024761: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803b00 of size 256 next 60\n",
      "2025-01-14 18:39:35.024765: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803c00 of size 256 next 61\n",
      "2025-01-14 18:39:35.024768: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803d00 of size 256 next 62\n",
      "2025-01-14 18:39:35.024772: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803e00 of size 256 next 63\n",
      "2025-01-14 18:39:35.024776: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803f00 of size 256 next 64\n",
      "2025-01-14 18:39:35.024780: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804000 of size 256 next 65\n",
      "2025-01-14 18:39:35.024784: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804100 of size 256 next 66\n",
      "2025-01-14 18:39:35.024787: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804200 of size 256 next 67\n",
      "2025-01-14 18:39:35.024791: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804300 of size 256 next 68\n",
      "2025-01-14 18:39:35.024795: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804400 of size 256 next 69\n",
      "2025-01-14 18:39:35.024798: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804500 of size 256 next 70\n",
      "2025-01-14 18:39:35.024802: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804600 of size 256 next 71\n",
      "2025-01-14 18:39:35.024806: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804700 of size 256 next 72\n",
      "2025-01-14 18:39:35.024809: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804800 of size 256 next 73\n",
      "2025-01-14 18:39:35.024813: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804900 of size 256 next 74\n",
      "2025-01-14 18:39:35.024817: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804a00 of size 256 next 75\n",
      "2025-01-14 18:39:35.024820: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804b00 of size 256 next 76\n",
      "2025-01-14 18:39:35.024823: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804c00 of size 256 next 77\n",
      "2025-01-14 18:39:35.024827: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804d00 of size 256 next 78\n",
      "2025-01-14 18:39:35.024830: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804e00 of size 256 next 79\n",
      "2025-01-14 18:39:35.024834: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804f00 of size 256 next 80\n",
      "2025-01-14 18:39:35.024837: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805000 of size 256 next 81\n",
      "2025-01-14 18:39:35.024841: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805100 of size 256 next 82\n",
      "2025-01-14 18:39:35.024845: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805200 of size 256 next 83\n",
      "2025-01-14 18:39:35.024849: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805300 of size 256 next 84\n",
      "2025-01-14 18:39:35.024852: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805400 of size 256 next 85\n",
      "2025-01-14 18:39:35.024855: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805500 of size 256 next 86\n",
      "2025-01-14 18:39:35.024859: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805600 of size 256 next 87\n",
      "2025-01-14 18:39:35.024862: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805700 of size 256 next 88\n",
      "2025-01-14 18:39:35.024865: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805800 of size 256 next 89\n",
      "2025-01-14 18:39:35.024869: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805900 of size 256 next 90\n",
      "2025-01-14 18:39:35.024873: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 304805a00 of size 2074112 next 18446744073709551615\n",
      "2025-01-14 18:39:35.024879: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 33554432\n",
      "2025-01-14 18:39:35.024883: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 304a00000 of size 33554432 next 18446744073709551615\n",
      "2025-01-14 18:39:35.024887: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 33554432\n",
      "2025-01-14 18:39:35.024891: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 306a00000 of size 33554432 next 18446744073709551615\n",
      "2025-01-14 18:39:35.024896: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 536870912\n",
      "2025-01-14 18:39:35.024900: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 308c00000 of size 536870912 next 18446744073709551615\n",
      "2025-01-14 18:39:35.024904: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 536870912\n",
      "2025-01-14 18:39:35.024908: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 328c00000 of size 536870912 next 18446744073709551615\n",
      "2025-01-14 18:39:35.024912: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2025-01-14 18:39:35.024919: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 90 Chunks of size 256 totalling 22.5KiB\n",
      "2025-01-14 18:39:35.024924: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 536870912 totalling 1.00GiB\n",
      "2025-01-14 18:39:35.024929: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 1.00GiB\n",
      "2025-01-14 18:39:35.024934: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 1142947840 memory_limit_: 68719476736 available bytes: 67576528896 curr_region_allocation_bytes_: 1073741824\n",
      "2025-01-14 18:39:35.024942: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                     68719476736\n",
      "InUse:                      1073764864\n",
      "MaxInUse:                   1073764864\n",
      "NumAllocs:                         141\n",
      "MaxAllocSize:                536870912\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-01-14 18:39:35.024955: W tensorflow/tsl/framework/bfc_allocator.cc:492] *_____*************************************xxxxxxxxxx************************************xxxxxxxxxxx\n",
      "2025-01-14 18:39:35.024985: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at gpu_swapping_kernels.cc:41 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_host_bfc\n",
      "2025-01-14 18:39:35.782904: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 1073741824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:35.782975: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 1073741824\n",
      "2025-01-14 18:39:35.848441: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 1073741824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:35.848496: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 1073741824\n",
      "2025-01-14 18:39:35.848516: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (gpu_host_bfc) ran out of memory trying to allocate 392.00MiB (rounded to 411041792)requested by op swap_out_gradient_tape/model_1/model/block1_conv1/ReluGrad_1\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-01-14 18:39:35.848526: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for gpu_host_bfc\n",
      "2025-01-14 18:39:35.848531: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 90, Chunks in use: 90. 22.5KiB allocated for chunks. 22.5KiB in use in bin. 1.3KiB client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848536: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848540: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848543: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848547: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848550: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848553: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848557: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848560: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848563: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848567: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848570: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848574: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 0. 1.98MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848577: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848581: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848584: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848587: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848593: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 2, Chunks in use: 0. 64.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848596: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848600: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848604: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 2. 1.00GiB allocated for chunks. 1.00GiB in use in bin. 784.00MiB client-requested in use in bin.\n",
      "2025-01-14 18:39:35.848609: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 392.00MiB was 256.00MiB, Chunk State: \n",
      "2025-01-14 18:39:35.848612: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 2097152\n",
      "2025-01-14 18:39:35.848617: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800000 of size 256 next 1\n",
      "2025-01-14 18:39:35.848620: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800100 of size 256 next 2\n",
      "2025-01-14 18:39:35.848623: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800200 of size 256 next 3\n",
      "2025-01-14 18:39:35.848625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800300 of size 256 next 4\n",
      "2025-01-14 18:39:35.848628: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800400 of size 256 next 5\n",
      "2025-01-14 18:39:35.848630: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800500 of size 256 next 6\n",
      "2025-01-14 18:39:35.848633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800600 of size 256 next 7\n",
      "2025-01-14 18:39:35.848635: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800700 of size 256 next 8\n",
      "2025-01-14 18:39:35.848638: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800800 of size 256 next 9\n",
      "2025-01-14 18:39:35.848640: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800900 of size 256 next 10\n",
      "2025-01-14 18:39:35.848643: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800a00 of size 256 next 11\n",
      "2025-01-14 18:39:35.848645: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800b00 of size 256 next 12\n",
      "2025-01-14 18:39:35.848648: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800c00 of size 256 next 13\n",
      "2025-01-14 18:39:35.848650: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800d00 of size 256 next 14\n",
      "2025-01-14 18:39:35.848653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800e00 of size 256 next 15\n",
      "2025-01-14 18:39:35.848655: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800f00 of size 256 next 16\n",
      "2025-01-14 18:39:35.848658: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801000 of size 256 next 17\n",
      "2025-01-14 18:39:35.848660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801100 of size 256 next 18\n",
      "2025-01-14 18:39:35.848663: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801200 of size 256 next 19\n",
      "2025-01-14 18:39:35.848665: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801300 of size 256 next 20\n",
      "2025-01-14 18:39:35.848668: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801400 of size 256 next 21\n",
      "2025-01-14 18:39:35.848670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801500 of size 256 next 22\n",
      "2025-01-14 18:39:35.848673: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801600 of size 256 next 23\n",
      "2025-01-14 18:39:35.848675: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801700 of size 256 next 24\n",
      "2025-01-14 18:39:35.848678: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801800 of size 256 next 25\n",
      "2025-01-14 18:39:35.848680: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801900 of size 256 next 26\n",
      "2025-01-14 18:39:35.848683: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801a00 of size 256 next 27\n",
      "2025-01-14 18:39:35.848685: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801b00 of size 256 next 28\n",
      "2025-01-14 18:39:35.848688: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801c00 of size 256 next 29\n",
      "2025-01-14 18:39:35.848690: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801d00 of size 256 next 30\n",
      "2025-01-14 18:39:35.848693: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801e00 of size 256 next 31\n",
      "2025-01-14 18:39:35.848695: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801f00 of size 256 next 32\n",
      "2025-01-14 18:39:35.848698: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802000 of size 256 next 33\n",
      "2025-01-14 18:39:35.848701: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802100 of size 256 next 34\n",
      "2025-01-14 18:39:35.848705: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802200 of size 256 next 35\n",
      "2025-01-14 18:39:35.848709: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802300 of size 256 next 36\n",
      "2025-01-14 18:39:35.848713: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802400 of size 256 next 37\n",
      "2025-01-14 18:39:35.848716: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802500 of size 256 next 38\n",
      "2025-01-14 18:39:35.848720: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802600 of size 256 next 39\n",
      "2025-01-14 18:39:35.848724: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802700 of size 256 next 40\n",
      "2025-01-14 18:39:35.848728: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802800 of size 256 next 41\n",
      "2025-01-14 18:39:35.848733: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802900 of size 256 next 42\n",
      "2025-01-14 18:39:35.848737: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802a00 of size 256 next 43\n",
      "2025-01-14 18:39:35.848740: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802b00 of size 256 next 44\n",
      "2025-01-14 18:39:35.848742: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802c00 of size 256 next 45\n",
      "2025-01-14 18:39:35.848745: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802d00 of size 256 next 46\n",
      "2025-01-14 18:39:35.848747: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802e00 of size 256 next 47\n",
      "2025-01-14 18:39:35.848750: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802f00 of size 256 next 48\n",
      "2025-01-14 18:39:35.848754: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803000 of size 256 next 49\n",
      "2025-01-14 18:39:35.848758: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803100 of size 256 next 50\n",
      "2025-01-14 18:39:35.848762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803200 of size 256 next 51\n",
      "2025-01-14 18:39:35.848766: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803300 of size 256 next 52\n",
      "2025-01-14 18:39:35.848770: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803400 of size 256 next 53\n",
      "2025-01-14 18:39:35.848775: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803500 of size 256 next 54\n",
      "2025-01-14 18:39:35.848778: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803600 of size 256 next 55\n",
      "2025-01-14 18:39:35.848780: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803700 of size 256 next 56\n",
      "2025-01-14 18:39:35.848783: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803800 of size 256 next 57\n",
      "2025-01-14 18:39:35.848785: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803900 of size 256 next 58\n",
      "2025-01-14 18:39:35.848788: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803a00 of size 256 next 59\n",
      "2025-01-14 18:39:35.848790: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803b00 of size 256 next 60\n",
      "2025-01-14 18:39:35.848793: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803c00 of size 256 next 61\n",
      "2025-01-14 18:39:35.848795: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803d00 of size 256 next 62\n",
      "2025-01-14 18:39:35.848798: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803e00 of size 256 next 63\n",
      "2025-01-14 18:39:35.848800: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803f00 of size 256 next 64\n",
      "2025-01-14 18:39:35.848804: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804000 of size 256 next 65\n",
      "2025-01-14 18:39:35.848808: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804100 of size 256 next 66\n",
      "2025-01-14 18:39:35.848813: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804200 of size 256 next 67\n",
      "2025-01-14 18:39:35.848816: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804300 of size 256 next 68\n",
      "2025-01-14 18:39:35.848819: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804400 of size 256 next 69\n",
      "2025-01-14 18:39:35.848822: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804500 of size 256 next 70\n",
      "2025-01-14 18:39:35.848826: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804600 of size 256 next 71\n",
      "2025-01-14 18:39:35.848830: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804700 of size 256 next 72\n",
      "2025-01-14 18:39:35.848834: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804800 of size 256 next 73\n",
      "2025-01-14 18:39:35.848838: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804900 of size 256 next 74\n",
      "2025-01-14 18:39:35.848842: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804a00 of size 256 next 75\n",
      "2025-01-14 18:39:35.848846: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804b00 of size 256 next 76\n",
      "2025-01-14 18:39:35.848851: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804c00 of size 256 next 77\n",
      "2025-01-14 18:39:35.848855: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804d00 of size 256 next 78\n",
      "2025-01-14 18:39:35.848858: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804e00 of size 256 next 79\n",
      "2025-01-14 18:39:35.848861: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804f00 of size 256 next 80\n",
      "2025-01-14 18:39:35.848863: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805000 of size 256 next 81\n",
      "2025-01-14 18:39:35.848865: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805100 of size 256 next 82\n",
      "2025-01-14 18:39:35.848868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805200 of size 256 next 83\n",
      "2025-01-14 18:39:35.848872: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805300 of size 256 next 84\n",
      "2025-01-14 18:39:35.848876: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805400 of size 256 next 85\n",
      "2025-01-14 18:39:35.848880: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805500 of size 256 next 86\n",
      "2025-01-14 18:39:35.848884: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805600 of size 256 next 87\n",
      "2025-01-14 18:39:35.848887: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805700 of size 256 next 88\n",
      "2025-01-14 18:39:35.848891: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805800 of size 256 next 89\n",
      "2025-01-14 18:39:35.848895: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805900 of size 256 next 90\n",
      "2025-01-14 18:39:35.848900: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 304805a00 of size 2074112 next 18446744073709551615\n",
      "2025-01-14 18:39:35.848905: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 33554432\n",
      "2025-01-14 18:39:35.848909: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 304a00000 of size 33554432 next 18446744073709551615\n",
      "2025-01-14 18:39:35.848914: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 33554432\n",
      "2025-01-14 18:39:35.848919: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 306a00000 of size 33554432 next 18446744073709551615\n",
      "2025-01-14 18:39:35.848924: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 536870912\n",
      "2025-01-14 18:39:35.848927: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 308c00000 of size 536870912 next 18446744073709551615\n",
      "2025-01-14 18:39:35.848930: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 536870912\n",
      "2025-01-14 18:39:35.848933: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 328c00000 of size 536870912 next 18446744073709551615\n",
      "2025-01-14 18:39:35.848936: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2025-01-14 18:39:35.848943: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 90 Chunks of size 256 totalling 22.5KiB\n",
      "2025-01-14 18:39:35.848949: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 536870912 totalling 1.00GiB\n",
      "2025-01-14 18:39:35.848954: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 1.00GiB\n",
      "2025-01-14 18:39:35.848959: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 1142947840 memory_limit_: 68719476736 available bytes: 67576528896 curr_region_allocation_bytes_: 1073741824\n",
      "2025-01-14 18:39:35.848967: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                     68719476736\n",
      "InUse:                      1073764864\n",
      "MaxInUse:                   1073764864\n",
      "NumAllocs:                         141\n",
      "MaxAllocSize:                536870912\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-01-14 18:39:35.848980: W tensorflow/tsl/framework/bfc_allocator.cc:492] *_____*************************************xxxxxxxxxx************************************xxxxxxxxxxx\n",
      "2025-01-14 18:39:35.849003: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at gpu_swapping_kernels.cc:41 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_host_bfc\n",
      "2025-01-14 18:39:35.928706: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 1073741824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:35.928757: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 1073741824\n",
      "2025-01-14 18:39:35.996060: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 1073741824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:35.996114: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 1073741824\n",
      "2025-01-14 18:39:36.826527: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 1073741824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:36.826571: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 1073741824\n",
      "2025-01-14 18:39:36.902535: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 1073741824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:36.902586: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 1073741824\n",
      "2025-01-14 18:39:36.902604: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (gpu_host_bfc) ran out of memory trying to allocate 392.00MiB (rounded to 411041792)requested by op swap_out_gradient_tape/model_1/model/block1_pool/MaxPool_1/MaxPoolGrad_0\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-01-14 18:39:36.902613: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for gpu_host_bfc\n",
      "2025-01-14 18:39:36.902618: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 90, Chunks in use: 90. 22.5KiB allocated for chunks. 22.5KiB in use in bin. 1.3KiB client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902622: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902626: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902629: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902632: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902635: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902638: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902641: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902645: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902648: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902651: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902654: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902657: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 0. 1.98MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902661: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902664: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902667: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902671: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902675: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 2, Chunks in use: 0. 64.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902678: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902681: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902685: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 2. 1.00GiB allocated for chunks. 1.00GiB in use in bin. 784.00MiB client-requested in use in bin.\n",
      "2025-01-14 18:39:36.902689: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 392.00MiB was 256.00MiB, Chunk State: \n",
      "2025-01-14 18:39:36.902692: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 2097152\n",
      "2025-01-14 18:39:36.902697: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800000 of size 256 next 1\n",
      "2025-01-14 18:39:36.902700: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800100 of size 256 next 2\n",
      "2025-01-14 18:39:36.902704: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800200 of size 256 next 3\n",
      "2025-01-14 18:39:36.902708: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800300 of size 256 next 4\n",
      "2025-01-14 18:39:36.902712: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800400 of size 256 next 5\n",
      "2025-01-14 18:39:36.902716: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800500 of size 256 next 6\n",
      "2025-01-14 18:39:36.902720: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800600 of size 256 next 7\n",
      "2025-01-14 18:39:36.902724: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800700 of size 256 next 8\n",
      "2025-01-14 18:39:36.902728: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800800 of size 256 next 9\n",
      "2025-01-14 18:39:36.902732: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800900 of size 256 next 10\n",
      "2025-01-14 18:39:36.902736: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800a00 of size 256 next 11\n",
      "2025-01-14 18:39:36.902740: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800b00 of size 256 next 12\n",
      "2025-01-14 18:39:36.902744: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800c00 of size 256 next 13\n",
      "2025-01-14 18:39:36.902748: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800d00 of size 256 next 14\n",
      "2025-01-14 18:39:36.902752: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800e00 of size 256 next 15\n",
      "2025-01-14 18:39:36.902756: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800f00 of size 256 next 16\n",
      "2025-01-14 18:39:36.902759: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801000 of size 256 next 17\n",
      "2025-01-14 18:39:36.902763: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801100 of size 256 next 18\n",
      "2025-01-14 18:39:36.902767: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801200 of size 256 next 19\n",
      "2025-01-14 18:39:36.902772: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801300 of size 256 next 20\n",
      "2025-01-14 18:39:36.902776: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801400 of size 256 next 21\n",
      "2025-01-14 18:39:36.902780: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801500 of size 256 next 22\n",
      "2025-01-14 18:39:36.902784: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801600 of size 256 next 23\n",
      "2025-01-14 18:39:36.902786: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801700 of size 256 next 24\n",
      "2025-01-14 18:39:36.902789: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801800 of size 256 next 25\n",
      "2025-01-14 18:39:36.902807: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801900 of size 256 next 26\n",
      "2025-01-14 18:39:36.902813: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801a00 of size 256 next 27\n",
      "2025-01-14 18:39:36.902817: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801b00 of size 256 next 28\n",
      "2025-01-14 18:39:36.902821: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801c00 of size 256 next 29\n",
      "2025-01-14 18:39:36.902826: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801d00 of size 256 next 30\n",
      "2025-01-14 18:39:36.902828: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801e00 of size 256 next 31\n",
      "2025-01-14 18:39:36.902831: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801f00 of size 256 next 32\n",
      "2025-01-14 18:39:36.902833: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802000 of size 256 next 33\n",
      "2025-01-14 18:39:36.902835: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802100 of size 256 next 34\n",
      "2025-01-14 18:39:36.902838: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802200 of size 256 next 35\n",
      "2025-01-14 18:39:36.902840: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802300 of size 256 next 36\n",
      "2025-01-14 18:39:36.902844: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802400 of size 256 next 37\n",
      "2025-01-14 18:39:36.902848: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802500 of size 256 next 38\n",
      "2025-01-14 18:39:36.902851: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802600 of size 256 next 39\n",
      "2025-01-14 18:39:36.902855: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802700 of size 256 next 40\n",
      "2025-01-14 18:39:36.902858: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802800 of size 256 next 41\n",
      "2025-01-14 18:39:36.902862: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802900 of size 256 next 42\n",
      "2025-01-14 18:39:36.902865: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802a00 of size 256 next 43\n",
      "2025-01-14 18:39:36.902869: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802b00 of size 256 next 44\n",
      "2025-01-14 18:39:36.902873: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802c00 of size 256 next 45\n",
      "2025-01-14 18:39:36.902877: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802d00 of size 256 next 46\n",
      "2025-01-14 18:39:36.902880: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802e00 of size 256 next 47\n",
      "2025-01-14 18:39:36.902884: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802f00 of size 256 next 48\n",
      "2025-01-14 18:39:36.902888: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803000 of size 256 next 49\n",
      "2025-01-14 18:39:36.902891: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803100 of size 256 next 50\n",
      "2025-01-14 18:39:36.902895: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803200 of size 256 next 51\n",
      "2025-01-14 18:39:36.902899: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803300 of size 256 next 52\n",
      "2025-01-14 18:39:36.902903: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803400 of size 256 next 53\n",
      "2025-01-14 18:39:36.902907: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803500 of size 256 next 54\n",
      "2025-01-14 18:39:36.902912: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803600 of size 256 next 55\n",
      "2025-01-14 18:39:36.902916: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803700 of size 256 next 56\n",
      "2025-01-14 18:39:36.902920: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803800 of size 256 next 57\n",
      "2025-01-14 18:39:36.902924: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803900 of size 256 next 58\n",
      "2025-01-14 18:39:36.902928: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803a00 of size 256 next 59\n",
      "2025-01-14 18:39:36.902933: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803b00 of size 256 next 60\n",
      "2025-01-14 18:39:36.902937: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803c00 of size 256 next 61\n",
      "2025-01-14 18:39:36.902941: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803d00 of size 256 next 62\n",
      "2025-01-14 18:39:36.902945: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803e00 of size 256 next 63\n",
      "2025-01-14 18:39:36.902949: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803f00 of size 256 next 64\n",
      "2025-01-14 18:39:36.902953: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804000 of size 256 next 65\n",
      "2025-01-14 18:39:36.902957: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804100 of size 256 next 66\n",
      "2025-01-14 18:39:36.902961: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804200 of size 256 next 67\n",
      "2025-01-14 18:39:36.902966: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804300 of size 256 next 68\n",
      "2025-01-14 18:39:36.902970: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804400 of size 256 next 69\n",
      "2025-01-14 18:39:36.902974: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804500 of size 256 next 70\n",
      "2025-01-14 18:39:36.902978: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804600 of size 256 next 71\n",
      "2025-01-14 18:39:36.902982: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804700 of size 256 next 72\n",
      "2025-01-14 18:39:36.902987: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804800 of size 256 next 73\n",
      "2025-01-14 18:39:36.902991: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804900 of size 256 next 74\n",
      "2025-01-14 18:39:36.902995: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804a00 of size 256 next 75\n",
      "2025-01-14 18:39:36.902999: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804b00 of size 256 next 76\n",
      "2025-01-14 18:39:36.903004: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804c00 of size 256 next 77\n",
      "2025-01-14 18:39:36.903008: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804d00 of size 256 next 78\n",
      "2025-01-14 18:39:36.903012: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804e00 of size 256 next 79\n",
      "2025-01-14 18:39:36.903016: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804f00 of size 256 next 80\n",
      "2025-01-14 18:39:36.903021: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805000 of size 256 next 81\n",
      "2025-01-14 18:39:36.903025: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805100 of size 256 next 82\n",
      "2025-01-14 18:39:36.903029: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805200 of size 256 next 83\n",
      "2025-01-14 18:39:36.903033: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805300 of size 256 next 84\n",
      "2025-01-14 18:39:36.903037: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805400 of size 256 next 85\n",
      "2025-01-14 18:39:36.903042: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805500 of size 256 next 86\n",
      "2025-01-14 18:39:36.903046: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805600 of size 256 next 87\n",
      "2025-01-14 18:39:36.903050: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805700 of size 256 next 88\n",
      "2025-01-14 18:39:36.903055: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805800 of size 256 next 89\n",
      "2025-01-14 18:39:36.903059: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805900 of size 256 next 90\n",
      "2025-01-14 18:39:36.903063: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 304805a00 of size 2074112 next 18446744073709551615\n",
      "2025-01-14 18:39:36.903068: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 33554432\n",
      "2025-01-14 18:39:36.903074: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 304a00000 of size 33554432 next 18446744073709551615\n",
      "2025-01-14 18:39:36.903078: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 33554432\n",
      "2025-01-14 18:39:36.903083: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 306a00000 of size 33554432 next 18446744073709551615\n",
      "2025-01-14 18:39:36.903088: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 536870912\n",
      "2025-01-14 18:39:36.903093: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 308c00000 of size 536870912 next 18446744073709551615\n",
      "2025-01-14 18:39:36.903097: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 536870912\n",
      "2025-01-14 18:39:36.903102: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 328c00000 of size 536870912 next 18446744073709551615\n",
      "2025-01-14 18:39:36.903106: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2025-01-14 18:39:36.903114: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 90 Chunks of size 256 totalling 22.5KiB\n",
      "2025-01-14 18:39:36.903120: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 536870912 totalling 1.00GiB\n",
      "2025-01-14 18:39:36.903125: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 1.00GiB\n",
      "2025-01-14 18:39:36.903130: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 1142947840 memory_limit_: 68719476736 available bytes: 67576528896 curr_region_allocation_bytes_: 1073741824\n",
      "2025-01-14 18:39:36.903138: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                     68719476736\n",
      "InUse:                      1073764864\n",
      "MaxInUse:                   1073764864\n",
      "NumAllocs:                         141\n",
      "MaxAllocSize:                536870912\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-01-14 18:39:36.903150: W tensorflow/tsl/framework/bfc_allocator.cc:492] *_____*************************************xxxxxxxxxx************************************xxxxxxxxxxx\n",
      "2025-01-14 18:39:36.903176: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at gpu_swapping_kernels.cc:41 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_host_bfc\n",
      "2025-01-14 18:39:46.068342: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 1073741824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:46.068397: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 1073741824\n",
      "2025-01-14 18:39:46.144865: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:798] failed to alloc 1073741824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-01-14 18:39:46.144910: W ./tensorflow/compiler/xla/stream_executor/device_host_allocator.h:46] could not allocate pinned host memory of size: 1073741824\n",
      "2025-01-14 18:39:46.144926: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (gpu_host_bfc) ran out of memory trying to allocate 392.00MiB (rounded to 411041792)requested by op swap_out_gradient_tape/model_1/model/block1_conv2/Conv2D_2/Conv2DBackpropFilter_0\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-01-14 18:39:46.144935: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for gpu_host_bfc\n",
      "2025-01-14 18:39:46.144940: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 90, Chunks in use: 90. 22.5KiB allocated for chunks. 22.5KiB in use in bin. 1.3KiB client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144945: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144948: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144951: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144954: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144957: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144960: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144963: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144966: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144969: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144972: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144975: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144979: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 0. 1.98MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144982: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144985: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144988: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144991: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144995: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 2, Chunks in use: 0. 64.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.144998: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.145001: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-14 18:39:46.145006: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 2. 1.00GiB allocated for chunks. 1.00GiB in use in bin. 784.00MiB client-requested in use in bin.\n",
      "2025-01-14 18:39:46.145010: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 392.00MiB was 256.00MiB, Chunk State: \n",
      "2025-01-14 18:39:46.145013: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 2097152\n",
      "2025-01-14 18:39:46.145018: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800000 of size 256 next 1\n",
      "2025-01-14 18:39:46.145021: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800100 of size 256 next 2\n",
      "2025-01-14 18:39:46.145023: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800200 of size 256 next 3\n",
      "2025-01-14 18:39:46.145025: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800300 of size 256 next 4\n",
      "2025-01-14 18:39:46.145027: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800400 of size 256 next 5\n",
      "2025-01-14 18:39:46.145030: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800500 of size 256 next 6\n",
      "2025-01-14 18:39:46.145032: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800600 of size 256 next 7\n",
      "2025-01-14 18:39:46.145034: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800700 of size 256 next 8\n",
      "2025-01-14 18:39:46.145036: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800800 of size 256 next 9\n",
      "2025-01-14 18:39:46.145039: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800900 of size 256 next 10\n",
      "2025-01-14 18:39:46.145041: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800a00 of size 256 next 11\n",
      "2025-01-14 18:39:46.145043: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800b00 of size 256 next 12\n",
      "2025-01-14 18:39:46.145045: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800c00 of size 256 next 13\n",
      "2025-01-14 18:39:46.145048: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800d00 of size 256 next 14\n",
      "2025-01-14 18:39:46.145050: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800e00 of size 256 next 15\n",
      "2025-01-14 18:39:46.145052: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304800f00 of size 256 next 16\n",
      "2025-01-14 18:39:46.145055: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801000 of size 256 next 17\n",
      "2025-01-14 18:39:46.145057: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801100 of size 256 next 18\n",
      "2025-01-14 18:39:46.145061: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801200 of size 256 next 19\n",
      "2025-01-14 18:39:46.145065: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801300 of size 256 next 20\n",
      "2025-01-14 18:39:46.145069: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801400 of size 256 next 21\n",
      "2025-01-14 18:39:46.145073: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801500 of size 256 next 22\n",
      "2025-01-14 18:39:46.145077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801600 of size 256 next 23\n",
      "2025-01-14 18:39:46.145080: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801700 of size 256 next 24\n",
      "2025-01-14 18:39:46.145084: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801800 of size 256 next 25\n",
      "2025-01-14 18:39:46.145088: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801900 of size 256 next 26\n",
      "2025-01-14 18:39:46.145091: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801a00 of size 256 next 27\n",
      "2025-01-14 18:39:46.145095: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801b00 of size 256 next 28\n",
      "2025-01-14 18:39:46.145099: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801c00 of size 256 next 29\n",
      "2025-01-14 18:39:46.145102: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801d00 of size 256 next 30\n",
      "2025-01-14 18:39:46.145106: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801e00 of size 256 next 31\n",
      "2025-01-14 18:39:46.145111: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304801f00 of size 256 next 32\n",
      "2025-01-14 18:39:46.145115: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802000 of size 256 next 33\n",
      "2025-01-14 18:39:46.145118: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802100 of size 256 next 34\n",
      "2025-01-14 18:39:46.145120: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802200 of size 256 next 35\n",
      "2025-01-14 18:39:46.145123: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802300 of size 256 next 36\n",
      "2025-01-14 18:39:46.145125: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802400 of size 256 next 37\n",
      "2025-01-14 18:39:46.145127: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802500 of size 256 next 38\n",
      "2025-01-14 18:39:46.145131: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802600 of size 256 next 39\n",
      "2025-01-14 18:39:46.145134: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802700 of size 256 next 40\n",
      "2025-01-14 18:39:46.145138: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802800 of size 256 next 41\n",
      "2025-01-14 18:39:46.145142: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802900 of size 256 next 42\n",
      "2025-01-14 18:39:46.145146: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802a00 of size 256 next 43\n",
      "2025-01-14 18:39:46.145149: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802b00 of size 256 next 44\n",
      "2025-01-14 18:39:46.145153: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802c00 of size 256 next 45\n",
      "2025-01-14 18:39:46.145157: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802d00 of size 256 next 46\n",
      "2025-01-14 18:39:46.145161: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802e00 of size 256 next 47\n",
      "2025-01-14 18:39:46.145164: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304802f00 of size 256 next 48\n",
      "2025-01-14 18:39:46.145166: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803000 of size 256 next 49\n",
      "2025-01-14 18:39:46.145169: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803100 of size 256 next 50\n",
      "2025-01-14 18:39:46.145171: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803200 of size 256 next 51\n",
      "2025-01-14 18:39:46.145173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803300 of size 256 next 52\n",
      "2025-01-14 18:39:46.145176: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803400 of size 256 next 53\n",
      "2025-01-14 18:39:46.145180: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803500 of size 256 next 54\n",
      "2025-01-14 18:39:46.145183: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803600 of size 256 next 55\n",
      "2025-01-14 18:39:46.145187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803700 of size 256 next 56\n",
      "2025-01-14 18:39:46.145191: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803800 of size 256 next 57\n",
      "2025-01-14 18:39:46.145194: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803900 of size 256 next 58\n",
      "2025-01-14 18:39:46.145198: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803a00 of size 256 next 59\n",
      "2025-01-14 18:39:46.145202: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803b00 of size 256 next 60\n",
      "2025-01-14 18:39:46.145206: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803c00 of size 256 next 61\n",
      "2025-01-14 18:39:46.145225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803d00 of size 256 next 62\n",
      "2025-01-14 18:39:46.145232: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803e00 of size 256 next 63\n",
      "2025-01-14 18:39:46.145236: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304803f00 of size 256 next 64\n",
      "2025-01-14 18:39:46.145241: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804000 of size 256 next 65\n",
      "2025-01-14 18:39:46.145245: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804100 of size 256 next 66\n",
      "2025-01-14 18:39:46.145248: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804200 of size 256 next 67\n",
      "2025-01-14 18:39:46.145252: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804300 of size 256 next 68\n",
      "2025-01-14 18:39:46.145256: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804400 of size 256 next 69\n",
      "2025-01-14 18:39:46.145260: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804500 of size 256 next 70\n",
      "2025-01-14 18:39:46.145264: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804600 of size 256 next 71\n",
      "2025-01-14 18:39:46.145267: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804700 of size 256 next 72\n",
      "2025-01-14 18:39:46.145271: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804800 of size 256 next 73\n",
      "2025-01-14 18:39:46.145275: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804900 of size 256 next 74\n",
      "2025-01-14 18:39:46.145279: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804a00 of size 256 next 75\n",
      "2025-01-14 18:39:46.145283: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804b00 of size 256 next 76\n",
      "2025-01-14 18:39:46.145287: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804c00 of size 256 next 77\n",
      "2025-01-14 18:39:46.145290: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804d00 of size 256 next 78\n",
      "2025-01-14 18:39:46.145294: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804e00 of size 256 next 79\n",
      "2025-01-14 18:39:46.145298: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304804f00 of size 256 next 80\n",
      "2025-01-14 18:39:46.145302: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805000 of size 256 next 81\n",
      "2025-01-14 18:39:46.145306: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805100 of size 256 next 82\n",
      "2025-01-14 18:39:46.145309: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805200 of size 256 next 83\n",
      "2025-01-14 18:39:46.145313: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805300 of size 256 next 84\n",
      "2025-01-14 18:39:46.145317: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805400 of size 256 next 85\n",
      "2025-01-14 18:39:46.145321: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805500 of size 256 next 86\n",
      "2025-01-14 18:39:46.145325: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805600 of size 256 next 87\n",
      "2025-01-14 18:39:46.145328: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805700 of size 256 next 88\n",
      "2025-01-14 18:39:46.145332: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805800 of size 256 next 89\n",
      "2025-01-14 18:39:46.145336: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 304805900 of size 256 next 90\n",
      "2025-01-14 18:39:46.145340: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 304805a00 of size 2074112 next 18446744073709551615\n",
      "2025-01-14 18:39:46.145345: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 33554432\n",
      "2025-01-14 18:39:46.145349: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 304a00000 of size 33554432 next 18446744073709551615\n",
      "2025-01-14 18:39:46.145353: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 33554432\n",
      "2025-01-14 18:39:46.145357: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 306a00000 of size 33554432 next 18446744073709551615\n",
      "2025-01-14 18:39:46.145362: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 536870912\n",
      "2025-01-14 18:39:46.145366: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 308c00000 of size 536870912 next 18446744073709551615\n",
      "2025-01-14 18:39:46.145370: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 536870912\n",
      "2025-01-14 18:39:46.145374: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 328c00000 of size 536870912 next 18446744073709551615\n",
      "2025-01-14 18:39:46.145378: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2025-01-14 18:39:46.145385: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 90 Chunks of size 256 totalling 22.5KiB\n",
      "2025-01-14 18:39:46.145390: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 536870912 totalling 1.00GiB\n",
      "2025-01-14 18:39:46.145395: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 1.00GiB\n",
      "2025-01-14 18:39:46.145399: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 1142947840 memory_limit_: 68719476736 available bytes: 67576528896 curr_region_allocation_bytes_: 1073741824\n",
      "2025-01-14 18:39:46.145407: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                     68719476736\n",
      "InUse:                      1073764864\n",
      "MaxInUse:                   1073764864\n",
      "NumAllocs:                         141\n",
      "MaxAllocSize:                536870912\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-01-14 18:39:46.145419: W tensorflow/tsl/framework/bfc_allocator.cc:492] *_____*************************************xxxxxxxxxx************************************xxxxxxxxxxx\n",
      "2025-01-14 18:39:46.145439: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at gpu_swapping_kernels.cc:41 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_host_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nOOM when allocating tensor with shape[32,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_host_bfc\n\t [[{{node swap_out_gradient_tape/model_1/model/block1_conv1/ReluGrad_1_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_3006]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_iter):\n\u001b[1;32m     12\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mget_batch(batch_size,num_targets)\n\u001b[0;32m---> 13\u001b[0m     loss_value\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtargets_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m ------------- \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIteration: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(loss_value))\n",
      "File \u001b[0;32m~/inz/src/models/visualphishnet/.venv/lib/python3.8/site-packages/keras/engine/training.py:2478\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2474\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[1;32m   2475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[1;32m   2476\u001b[0m     )\n\u001b[1;32m   2477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[0;32m-> 2478\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2480\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/inz/src/models/visualphishnet/.venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/inz/src/models/visualphishnet/.venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nOOM when allocating tensor with shape[32,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_host_bfc\n\t [[{{node swap_out_gradient_tape/model_1/model/block1_conv1/ReluGrad_1_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_3006]"
     ]
    }
   ],
   "source": [
    "# run = wandb.init(\n",
    "#     project=\"Inz\",\n",
    "#     notes=f\"VisualPhish smallerSampleDataset\",\n",
    "#     config={**model_config, **dataset_config, **training_config}\n",
    "# )\n",
    "\n",
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "targets_train = np.zeros([batch_size,1])\n",
    "for i in range(1, n_iter):\n",
    "    inputs=get_batch(batch_size,num_targets)\n",
    "    loss_value=model.train_on_batch(inputs,targets_train)\n",
    "    \n",
    "    print(\"\\n ------------- \\n\")\n",
    "    print('Iteration: '+ str(i) +'. '+ \"Loss: {0}\".format(loss_value))\n",
    "    # run.log({\"loss\": loss_value})\n",
    "\n",
    "    if i % save_interval == 0:\n",
    "        save_keras_model(model)\n",
    "\n",
    "    if i % lr_interval == 0:\n",
    "        start_lr = 0.99*start_lr\n",
    "        K.set_value(model.optimizer.lr, start_lr)\n",
    "        # run.log({\"lr\": start_lr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f80a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.abspath(output_dir)\n",
    "run.log_model(os.path.join(path, 'model.h5'), name=\"VP-Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9496817c388a8d68",
   "metadata": {},
   "source": [
    "# Calculate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca43e5ed81c653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_model = model.layers[3]\n",
    "\n",
    "whitelist_emb = shared_model.predict(X_train_legit,batch_size=64)\n",
    "np.save(output_dir+'whitelist_emb',whitelist_emb)\n",
    "np.save(output_dir+'whitelist_labels',y_train_legit)\n",
    "\n",
    "phishing_emb = shared_model.predict(all_imgs_test,batch_size=64)\n",
    "np.save(output_dir+'phishing_emb',phishing_emb)\n",
    "np.save(output_dir+'phishing_labels',all_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf96827",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact=wandb.Artifact(name='VisualPhish-phase-1', type='embeddings')\n",
    "\n",
    "artifact.add_file(os.path.join(output_dir, 'whitelist_emb.npy'), 'whitelist_emb')\n",
    "artifact.add_file(os.path.join(output_dir, 'whitelist_labels.npy'), 'whitelist_labels')\n",
    "artifact.add_file(os.path.join(output_dir, 'phishing_emb.npy'), 'phishing_emb')\n",
    "artifact.add_file(os.path.join(output_dir, 'phishing_labels.npy'), 'phishing_labels')\n",
    "run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6904e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
